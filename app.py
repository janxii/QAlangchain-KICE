import threading
from flask import Flask, request, jsonify
from datetime import datetime
import streamlit as st
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
import os
import requests
import pytz

# Flask ë¶€ë¶„

app = Flask(__name__)

API_CALL_LIMIT = 10
ip_data = {}
korea_timezone = pytz.timezone('Asia/Seoul')

@app.route('/api/call', methods=['POST'])
def api_call():
    ip = request.remote_addr
    # í˜„ì¬ ì‹œê°„ì„ í•œêµ­ ì‹œê°„ëŒ€ë¡œ ê°€ì ¸ì˜´
    current_time = datetime.now(korea_timezone)
    current_date = current_time.date()
    # IPê°€ ê¸°ë¡ë˜ì§€ ì•Šì•˜ì„ ë•Œ ì´ˆê¸°í™”
    if ip not in ip_data:
        ip_data[ip] = {'count': 0, 'last_date': None}

    # í˜„ì¬ ë‚ ì§œê°€ ë§ˆì§€ë§‰ í˜¸ì¶œì¼ê³¼ ë‹¤ë¥¼ ê²½ìš° ì´ˆê¸°í™”
    if ip_data[ip]['last_date'] != current_date:
        ip_data[ip]['count'] = 0
        ip_data[ip]['last_date'] = current_date

    # API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ í™•ì¸
    if ip_data[ip]['count'] < API_CALL_LIMIT:
        ip_data[ip]['count'] += 1  # í˜¸ì¶œ íšŸìˆ˜ ì¦ê°€
        return jsonify(success=True, count=ip_data[ip]['count'])
    else:
        return jsonify(success=False, message="í•˜ë£¨ API í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")

def run_flask():
    app.run(port=5001)  # í¬íŠ¸ ë²ˆí˜¸ë¥¼ 5001ë¡œ ë³€ê²½

flask_thread = threading.Thread(target=run_flask)
flask_thread.start()

# Flask ì„œë²„ì˜ ê³µìš© URLì„ ì„¤ì •í•©ë‹ˆë‹¤. ìœ„ì˜ ì…€ì—ì„œ ì¶œë ¥ëœ URLë¡œ ë³€ê²½í•´ì•¼ í•œë‹¤
FLASK_SERVER_URL = "http://localhost:5001"  # ì˜ˆ: "http://12345678.ngrok.io"

# API í‚¤ ì„¤ì • ë° ì´ˆê¸°í™”
os.environ["OPENAI_API_KEY"] = st.secrets["api_key"]

vectordb = Chroma(persist_directory='./db', embedding_function=OpenAIEmbeddings())
retriever = vectordb.as_retriever(search_kwargs={"k": 3})
qa_chain_global = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=0),
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

st.title(':mag_right: Streamlit QAì±—ë´‡')
chat_history = []
user_input = st.text_input(label=':seedling: ë‹¹ì‹ ì´ ê¶ê¸ˆí•œ ê²ƒì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”!', placeholder='QAê²€ìƒ‰')

# Send ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê³µì§€ì‚¬í•­ì„ ìˆ¨ê¹€
if st.button("Send"):
    st.session_state.show_notice = False  

if 'show_notice' not in st.session_state or st.session_state.show_notice:
    st.write("ğŸ“¢ 2017í•™ë…„ë„ ~ 2024í•™ë…„ë„ í‰ê°€ì› ë¹„ë¬¸í•™ ì§€ë¬¸ì— ë¬»ê³  ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤")
    st.write("ğŸ“Œ êµ¬ì²´ì ìœ¼ë¡œ ë¬¼ì–´ë³¼ìˆ˜ë¡ ë” ìì„¸í•˜ê²Œ ë‹µí•©ë‹ˆë‹¤")
    st.write("ğŸ“Œ ë°©ëŒ€í•œ ë¹„ë¬¸í•™ ë¬¸ì„œì—ì„œ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ì„œ ëŒ€ë‹µí•©ë‹ˆë‹¤!")
    st.session_state.show_notice = True

if not st.session_state.show_notice:
    with st.spinner("Waiting for QAì±—ë´‡..."):
        if user_input:
            response = requests.post(FLASK_SERVER_URL + "/api/call")
            data = response.json()

            if data["success"]:
                chat_history.append({"user": user_input})
                llm_response = qa_chain_global(user_input + " ë‘ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ~ë‹¤ë¡œ ë¬¸ì¥ì„ ë¬´ì¡°ê±´ì ìœ¼ë¡œ ëë§ºì–´ì¤˜")
                bot_response = llm_response['result']
                chat_history.append({"bot": bot_response})

                for message in chat_history:
                    if "user" in message:
                        st.write(":green[You]: ", message["user"])
                    else:
                        st.write(":blue[Bot]: ", message["bot"])
                        st.write('\n\nSources:')
                        for source in llm_response["source_documents"]:
                            st.write(source.metadata['source'])
            else:
                st.warning(f"API í˜¸ì¶œ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤! í•˜ë£¨ì— {API_CALL_LIMIT}ë²ˆë§Œ APIë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
